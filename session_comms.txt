kafka-topics --zookeeper localhost:2181 --list
kafka-console-consumer --bootstrap-server localhost:9092 --topic ide-topic --from-beginning
kafka-topics --zookeeper localhost:2181 --create --topic ide-topic-wkey --partitions 3 --replication-factor 1
gedit /home/samar/confluent/etc/kafka/server/properties
replace #advertised.listeners host with ip of machine found using ifconfig
and change 
num.partitions=1 
to 
num.partitions=3
save and close
/home/samar/data/201819/fo/fo01JAN2018bhav.csv
schema-registry-start -daemon /home/samar/confluent/etc/schema-registry/schema-registry.properties
git clone https://github.com/samarkk/kafka-python-examples.git

hdfs  --daemon start namenode
hdfs --damon start datanode
jps
hdfs dfsadmin -safemode get
hdfs dfs -ls 
hdfs dfs -ls /user/samar

apache-cassandra-3.11.11-bin/bin/cassandra

# stat cql
apache-cassandra-3.11.11-bin/bin/cassandra


 create keyspace finks with replication = {'class': 'SimpleStrategy', 'replication_factor': 1}';
 
 CREATE TABLE finks.fotable (
    symbol text,
    expiry date,
    trdate date,
    instrument text,
    option_typ text,
    strike_pr decimal,
    chgoi int,
    contracts int,
    cpr decimal,
    oi int,
    trdval decimal,
    tstamp timestamp,
    PRIMARY KEY ((symbol, expiry), trdate, instrument, option_typ, strike_pr)
);

# in a terminal
pip install cassandra-driver

# start yarn daemons
yarn --daemon start resourcemanager
yarn --daemon start nodemanager


hadoop jar /home/samar/hadoop330/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount fwc.txt wcount

file_for_word_count = 'fwc.txt'
sc.textFile(file_for_word_count).flatMap(lambda x: x.split(' ')).filter(lambda x: x != '').map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda x: -x[1]).take(20)

cd /home/samar
rm -rf /home/samar/spark-python
git clone https://github.com/samarkk/spark-python
gedit /home/samar/spark-python/SparkLogProcessor.py

spark-submit /home/samar/spark-python/SparkLogProcessor.py

hive --service metastore 2>&1 &>/dev/null &

echo "set enable-bracketed-paste off" >> /home/samar/.inputrc

# refresh the spark-python director - execute lines 59 to 61
mysql -u root -p'puneetRai10198)' --local-infile < /home/samar/spark-python/scripts/mysql_mock_table_creation.sql

# login to mysql 
mysql -u root -p'puneetRai10198)' testdb
